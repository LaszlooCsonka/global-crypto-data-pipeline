# global-crypto-data-pipeline
End-to-End Big Data Pipeline for Crypto Markets. Built with Python, PySpark, Airflow, and Docker. Architected for GCP (BigQuery, Dataproc, GKE) using Data Vault 2.0 modeling.


# Global Crypto Data Platform (Enterprise Edition)

## üìå Project Overview
Ez a projekt egy professzion√°lis, v√©gpontt√≥l-v√©gpontig tart√≥ (End-to-End) Big Data platform, amely kriptovaluta piaci adatokat gy≈±jt, tiszt√≠t √©s elemez. A rendszer c√©lja egy sk√°l√°zhat√≥ architekt√∫ra bemutat√°sa, amely a lok√°lis adatgy≈±jt√©st≈ël a felh≈ëalap√∫ (GCP) Big Data feldolgoz√°sig terjed.

A projekt fejleszt√©se sor√°n a szoftverfejleszt√©si √©letciklust (SDLC) **Jira**-ban dokument√°lom, a folyamatokat pedig **BPMN 2.0** √©s **UML** √°br√°kkal tervezem.

## üõ† Tech Stack
- **Orchestration:** Apache Airflow
- **Containerization:** Docker, Kubernetes (GKE)
- **Data Processing:** Python, PySpark (Google Cloud Dataproc)
- **Cloud Platform:** Google Cloud Platform (GCP)
- **Storage & Warehouse:** Google Cloud Storage (Data Lake), BigQuery (DWH)
- **Data Modeling:** Data Vault 2.0, Apache Iceberg
- **Databases:** RDBMS (SQL) & NoSQL elvek
- **Documentation:** Jira, BPMN, UML

## üèó Architecture & Roadmap

A projekt n√©gy f≈ë f√°zisra oszlik:

### Phase 1: Ingestion & Local Automation
- Binance REST API integr√°ci√≥ Pythonban.
- Helyi √ºtemez√©s √©s hibakezel√©s implement√°l√°sa.
- BPMN folyamattervez√©s a logikai √∫tvonalhoz.

### Phase 2: Cloud Infrastructure & Data Modeling
- √Ått√©r√©s **Google Cloud Storage** alap√∫ Data Lake-re.
- **Data Vault 2.0** modellez√©s (Hubs, Satellites, Links) alkalmaz√°sa a historikus adatok integrit√°s√°√©rt.
- **RDBMS** metaadat-kezel√©s √©s **NoSQL** log-t√°rol√°s.

### Phase 3: Big Data Processing
- **PySpark** ETL folyamatok fejleszt√©se nagy t√∂meg≈± adatok tiszt√≠t√°s√°ra.
- **Apache Iceberg** t√°blaform√°tum haszn√°lata (ACID tranzakci√≥k √©s Time Travel).
- Er≈ëforr√°s-kezel√©s **Google Cloud Dataproc** haszn√°lat√°val.

### Phase 4: Enterprise Analytics & Orchestration
- Adatt√°rh√°z (DWH) √©p√≠t√©s **BigQuery**-ben.
- Munkafolyamatok vez√©rl√©se **Apache Airflow** seg√≠ts√©g√©vel.
- A teljes rendszer sk√°l√°z√°sa **Kubernetes (GKE)** k√∂rnyezetbe.

## üìà Data Vault 2.0 Model
A projekt sor√°n **Data Vault 2.0** m√≥dszertant haszn√°lok, amely lehet≈ëv√© teszi a rendk√≠v√ºl rugalmas √©s sk√°l√°zhat√≥ adatt√°rol√°st. 
- **Hubs:** √úzleti kulcsok (pl. Coin symbols).
- **Satellites:** Id≈ëf√ºgg≈ë adatok (pl. √Årfolyam, volumen).
- **Links:** Kapcsolatok (pl. Exchange-to-Pair rel√°ci√≥k).

## üöÄ How to Run (Local Setup)
*(Felt√∂lt√©s alatt - hamarosan Docker Compose √°llom√°nyokkal)*

## üìÑ Documentation
A projekt r√©szletes technikai tervei √©s Jira jegyei a `/docs` mapp√°ban tal√°lhat√≥ak.
